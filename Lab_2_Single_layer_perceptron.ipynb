{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Actulus/MI/blob/main/Lab_2_Single_layer_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Megoldandó feladatok (amelyeket be kell küldeni):\n",
        "\n",
        "I.\n",
        "1.   Implementáld le a (AND, OR, XOR, NAND, NOR, XNOR) logikákat.\n",
        "\n",
        "  Több segítség az alábbi linken: https://www.techtarget.com/whatis/definition/logic-gate-AND-OR-XOR-NOT-NAND-NOR-and-XNOR\n",
        "2.   Változtass a \"w\" súlyzó adatokon. Milyen szerepet játszik a  \"w\" paraméter értéke?\n",
        "\n",
        "> * A \"w\" paraméter a súlyozásban játszik szerepet, a bemeneti változók súlyozott összegét határozza meg. Ezek befolyásolják a modell tanulási folyamatát és pontosságát.\n",
        "\n",
        "3.   Változtass a \"learning_rate\"-et. Milyen szerepet játszik a  \"learning_rate\" paraméter értéke?\n",
        "\n",
        "> * A \"learning_rate\" paramétere határozza meg a súlyzók változását a visszaterjesztéskor, a tanulási folyamat sebességét és konvergenciáját határozza meg. Ha túl kicsi, akkor a tanítás egy hosszú folyamat, olykor túl hosszú.\n",
        "\n",
        "4.   Rövöden írd le, hogy a \"global_delta\" milyen célt szolgál?\n",
        "\n",
        "> * A \"global_delta\" meghatározza a hiba globális változását az epochok alatt. A tanulás haladását méri.\n",
        "\n",
        "5.   Rövöden írd le, hogy a \"epoch\" milyen célt szolgál?\n",
        "\n",
        "> * Az \"epoch\" meghatározza, hogy hány \"kört\" fut a program, hányszor tesztelődik az adathalmazon. Az időtartamot és a modell pontosságát befolyásolja. Az epochok alatt frissúl a súlytényező.\n",
        "\n",
        "6.   Hogyan változik a W paraméter a ciklusban? Milyen szabály alapján?\n",
        "\n",
        "> * A W paraméter a ciklusban az algoritmus tanulásával együtt változik, annak érdekében, hogy minimalizálják a hibát. A gradient descent szabály alapján történik, ami a hiba függvényének deriváltját használja a súlyzók javítására.\n",
        "\n",
        "7.   Mi a különbség a Perceptron és az Adaline között?\n",
        "\n",
        "> * A Perceptron csak akkor változtatja a súlytényezőit, ha hibát talált, az Adaline \"folyamatosan\" javítja a súlytényezőit, nem csak akkor javít, ha hibát talál. A Perceptron csak -1 vagy 1 értéket ad vissza, míg az Adeline folytonos kimenetet ad.\n",
        "\n",
        "8. Melyek ezek közül (AND, OR, XOR, stb.), amiket a Percetron logika meg tud oldani?\n",
        "\n",
        "> * Az AND és az OR, a többi túl komplex a Perceptronnak.\n",
        "\n"
      ],
      "metadata": {
        "id": "b4c2F-ewokyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Implementáld le az AND logikákat.*** ✈"
      ],
      "metadata": {
        "id": "rsfRxGhbcQPo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nSeFNKRxrJiw"
      },
      "outputs": [],
      "source": [
        "# This code just uses numpy for array and matrix representation.\n",
        "import numpy as np\n",
        "\n",
        "#https://sefiks.com/2020/01/04/a-step-by-step-perceptron-example/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# `atributes` variable define input array and `labels`(output) array are selected base on the operator.\n",
        "atributes = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "dXiZWjbwrUin"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which operator you are going to use. This can be `and`, `or`, `xor`, `nand`, `nor`, `xnor`.\n",
        "operator = 'or'"
      ],
      "metadata": {
        "id": "NU8rLbSh0S4L"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if operator == 'and':\n",
        "    labels = np.array([0, 0, 0, 1]) #AND Gate\n",
        "elif operator == 'or':\n",
        "  labels = np.array([0, 1, 1, 1]) # OR Gate\n",
        "elif operator == 'xor':\n",
        "  labels = np.array([0, 1, 1, 0]) # XOR Gate\n",
        "elif operator == 'nand':\n",
        "   labels = np.array([1, 1, 1, 0]) #NAND Gate\n",
        "elif operator == 'nor':\n",
        "  labels = np.array([1, 0, 0, 0])\n",
        "elif operator == 'xnor':\n",
        "  labels = np.array([1, 0, 0, 1])\n"
      ],
      "metadata": {
        "id": "Q77fSv6zrhQD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------\n",
        "\n",
        "# `w` define weight of the perceptron,  `threshold` define a umbral, `alpha` is a learning rate, `epoch` is a number of process to train the model.\n",
        "w = [+9, +9] #initial random values for weights\n",
        "# w = [+20, +20]\n",
        "\n",
        "threshold = 0.5\n",
        "alpha = 0.5 #learning rate, ha tul nagy, akkor a program elszáll, érdemes minél kisebb legyen, akkor több epoch-al fut le\n",
        "epoch = 10 #learning time, kipróbálni 1000-re\n",
        "#----------------"
      ],
      "metadata": {
        "id": "RJ6uTFz2rmEp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, epoch):\n",
        "    print(\"epoch \",  i+1)\n",
        "    global_delta = 0 #this variable is used to terminate the for loop if learning completed in early epoch\n",
        "    for j in range(len(atributes)):\n",
        "        actual = labels[j]\n",
        "        instance = atributes[j]\n",
        "\n",
        "        x0 = instance[0]\n",
        "        x1 = instance[1]\n",
        "\n",
        "        sum_unit = x0 * w[0] + x1 * w[1]\n",
        "\n",
        "        if sum_unit > threshold:\n",
        "            predicted  = 1\n",
        "        else:\n",
        "            predicted  = 0\n",
        "\n",
        "        delta = actual - predicted\n",
        "        global_delta = global_delta + abs(delta)\n",
        "\n",
        "        #update weights with respect to the error\n",
        "        w[0] = w[0] + delta * alpha\n",
        "        w[1] = w[1] + delta * alpha\n",
        "\n",
        "        print(x0,\" \", operator, \" \", x1, \" -> actual: \", actual, \", predicted: \", predicted, \" (w: \",w[0],\")\")\n",
        "\n",
        "    if global_delta == 0:\n",
        "        break\n",
        "\n",
        "    print(\"----------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRwIX2-urp9O",
        "outputId": "dec93485-d1c1-44e1-8327-23835ecd0ca8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  1\n",
            "0   xor   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   xor   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  2\n",
            "0   xor   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   xor   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  3\n",
            "0   xor   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   xor   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  4\n",
            "0   xor   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   xor   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  5\n",
            "0   xor   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   xor   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  6\n",
            "0   xor   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   xor   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  7\n",
            "0   xor   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   xor   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  8\n",
            "0   xor   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   xor   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  9\n",
            "0   xor   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   xor   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  10\n",
            "0   xor   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   xor   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   xor   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtf_pbnAuZP9",
        "outputId": "25d66f76-9619-4c0d-a2a3-2443f33bd851"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9.0, 9.0]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}