{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Actulus/MI/blob/main/Lab_2_Single_layer_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Megoldandó feladatok (amelyeket be kell küldeni):\n",
        "\n",
        "I.\n",
        "1.   Implementáld le a (AND, OR, XOR, NAND, NOR, XNOR) logikákat.\n",
        "\n",
        "  Több segítség az alábbi linken: https://www.techtarget.com/whatis/definition/logic-gate-AND-OR-XOR-NOT-NAND-NOR-and-XNOR\n",
        "2.   Változtass a \"w\" súlyzó adatokon. Milyen szerepet játszik a  \"w\" paraméter értékei?\n",
        "3.   Változtass a \"learning_rate\"-et. Milyen szerepet játszik a  \"learning_rate\" paraméter értékei?\n",
        "4.   Rövöden írd le, hogy a \"global_delta\" milyen célt szolgál?\n",
        "5.   Rövöden írd le, hogy a \"epoch\" milyen célt szolgál?\n",
        "6.   Hogyan változik a W paraméter a ciklusban? Milyen szabály alapján?\n",
        "7.   Mi a különbség a Perceptron és az Adaline között?\n",
        "\n"
      ],
      "metadata": {
        "id": "b4c2F-ewokyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Implementáld le az AND logikákat.*** ✈"
      ],
      "metadata": {
        "id": "rsfRxGhbcQPo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSeFNKRxrJiw"
      },
      "outputs": [],
      "source": [
        "# This code just uses numpy for array and matrix representation.\n",
        "import numpy as np\n",
        "\n",
        "#https://sefiks.com/2020/01/04/a-step-by-step-perceptron-example/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# `atributes` variable define input array and `labels`(output) array are selected base on the operator.\n",
        "atributes = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "dXiZWjbwrUin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which operator you are going to use. This can be `and`, `or`, `xor`, `nand`, `nor`, `xnor`.\n",
        "operator = 'nand'"
      ],
      "metadata": {
        "id": "NU8rLbSh0S4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if operator == 'and':\n",
        "    labels = np.array([0, 0, 0, 1]) #AND Gate\n",
        "elif operator == 'nand':\n",
        "    labels = np.array([1,1, 1, 0]) #AND Gate"
      ],
      "metadata": {
        "id": "Q77fSv6zrhQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------\n",
        "\n",
        "# `w` define weight of the perceptron,  `threshold` define a umbral, `alpha` is a learning rate, `epoch` is a number of process to train the model.\n",
        "w = [+9, +9] #initial random values for weights\n",
        "\n",
        "threshold = 0.5\n",
        "alpha = 0.5 #learning rate\n",
        "epoch = 10 #learning time\n",
        "#----------------"
      ],
      "metadata": {
        "id": "RJ6uTFz2rmEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, epoch):\n",
        "    print(\"epoch \",  i+1)\n",
        "    global_delta = 0 #this variable is used to terminate the for loop if learning completed in early epoch\n",
        "    for j in range(len(atributes)):\n",
        "        actual = labels[j]\n",
        "        instance = atributes[j]\n",
        "\n",
        "        x0 = instance[0]\n",
        "        x1 = instance[1]\n",
        "\n",
        "        sum_unit = x0 * w[0] + x1 * w[1]\n",
        "\n",
        "        if sum_unit > threshold:\n",
        "            predicted  = 1\n",
        "        else:\n",
        "            predicted  = 0\n",
        "\n",
        "        delta = actual - predicted\n",
        "        global_delta = global_delta + abs(delta)\n",
        "\n",
        "        #update weights with respect to the error\n",
        "        w[0] = w[0] + delta * alpha\n",
        "        w[1] = w[1] + delta * alpha\n",
        "\n",
        "        print(x0,\" \", operator, \" \", x1, \" -> actual: \", actual, \", predicted: \", predicted, \" (w: \",w[0],\")\")\n",
        "\n",
        "    if global_delta == 0:\n",
        "        break\n",
        "\n",
        "    print(\"----------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRwIX2-urp9O",
        "outputId": "01c5966c-b50c-4156-9a93-4405ef76831e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  1\n",
            "0   nand   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   nand   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  2\n",
            "0   nand   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   nand   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  3\n",
            "0   nand   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   nand   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  4\n",
            "0   nand   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   nand   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  5\n",
            "0   nand   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   nand   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  6\n",
            "0   nand   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   nand   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  7\n",
            "0   nand   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   nand   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  8\n",
            "0   nand   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   nand   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  9\n",
            "0   nand   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   nand   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n",
            "epoch  10\n",
            "0   nand   0  -> actual:  1 , predicted:  0  (w:  9.5 )\n",
            "0   nand   1  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   0  -> actual:  1 , predicted:  1  (w:  9.5 )\n",
            "1   nand   1  -> actual:  0 , predicted:  1  (w:  9.0 )\n",
            "----------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtf_pbnAuZP9",
        "outputId": "5b72a2a5-de2a-43d5-90e3-891b85471b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9.0, 9.0]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}